{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xor task\n",
    "xor_data = np.array([[1, 0],\n",
    "                    [0, 1],\n",
    "                    [1, 1],\n",
    "                    [0, 0]])\n",
    "xor_label = np.array([[1], [1], [0], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  19999\n",
      "Hypothesis  [[0.85836625]\n",
      " [0.8545869 ]\n",
      " [0.17017888]\n",
      " [0.10559744]]\n",
      "Theta1  [[ 0.14300452  0.7830573   3.7792304   0.21455818  0.16214927  2.144812\n",
      "   0.18659179 -0.03180014  1.1321781  -1.0074774  -0.157866   -0.2630893\n",
      "  -0.7917679   0.8725356   1.5414064   0.14288256 -0.18899837 -0.49919847\n",
      "  -0.45449406  0.5581853  -1.7585096   2.7437491  -0.5511488   0.10902152\n",
      "  -2.753455    0.30134913 -0.4575635  -0.0364867  -0.94139856 -1.5982351 ]\n",
      " [ 0.7135928   0.15387589 -2.9494364  -0.3424827  -0.75019926  2.2385962\n",
      "  -0.11019188 -0.25981072 -0.34282792 -0.03722726  0.5549921   0.6134684\n",
      "   0.40972045  0.16483898 -0.6502068  -0.20751597  0.4792363  -0.678674\n",
      "  -0.7251267  -0.5996201  -1.894942    2.688422   -0.21433839 -0.5128222\n",
      "   3.6089613  -0.84492713 -0.12132396 -0.31417677  0.42025536  2.450662  ]]\n",
      "Bias1  [-0.24817428  0.08220017  1.5750337  -0.04076822 -0.03829433  0.0695172\n",
      "  0.03043243  0.05665643  0.19583584  0.19161753  0.10425753 -0.00969029\n",
      " -0.3269017  -0.2614341   0.40185115 -0.03653141  0.05684634  0.1428674\n",
      " -0.14234155 -0.28108552 -0.2710707  -0.28033438  0.23433289 -0.06392456\n",
      "  1.4940597  -0.1986839   0.09486791  0.04109846 -0.3401383   0.98820555]\n",
      "Theta2  [[-0.84831494]\n",
      " [ 0.4535698 ]\n",
      " [-4.081547  ]\n",
      " [ 0.71965504]\n",
      " [ 0.5949448 ]\n",
      " [ 2.2932127 ]\n",
      " [ 0.5226558 ]\n",
      " [ 0.98318756]\n",
      " [-1.0204555 ]\n",
      " [ 0.8032397 ]\n",
      " [-0.6720009 ]\n",
      " [ 0.12182844]\n",
      " [ 1.202076  ]\n",
      " [-0.4608155 ]\n",
      " [-1.3012137 ]\n",
      " [-0.5220288 ]\n",
      " [-0.25568542]\n",
      " [ 0.37553754]\n",
      " [-0.10117509]\n",
      " [ 0.66874844]\n",
      " [-1.5864849 ]\n",
      " [ 3.27138   ]\n",
      " [ 1.2782949 ]\n",
      " [ 1.0884475 ]\n",
      " [-3.7126517 ]\n",
      " [ 0.8930129 ]\n",
      " [ 0.85095984]\n",
      " [ 0.8333804 ]\n",
      " [ 1.2117254 ]\n",
      " [-1.9754871 ]]\n",
      "Bias2  [0.3470139]\n",
      "cost  0.15200149\n",
      "accuracy:  1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://aimatters.wordpress.com/2016/01/16/solving-xor-with-a-neural-network-in-tensorflow/\n",
    "with tf.Graph().as_default() as g:\n",
    "    x_input = tf.placeholder( tf.float32 ,  [None, 2] , name='x_input' )\n",
    "    y_label = tf.placeholder( tf.float32 , [None, 1] , name='y_label' )\n",
    "    \n",
    "    # start building your model and meet the requirements\n",
    "    # from here\n",
    "    number_hidden_nodes = 30\n",
    "    Theta1 = tf.Variable(tf.random_uniform([2,number_hidden_nodes], -1, 1), name = \"Theta1\")\n",
    "    Theta2 = tf.Variable(tf.random_uniform([number_hidden_nodes,1], -1, 1), name = \"Theta2\")\n",
    "    Bias1 = tf.Variable(tf.zeros([number_hidden_nodes]), name = \"Bias1\")\n",
    "    Bias2 = tf.Variable(tf.zeros([1]), name = \"Bias2\")\n",
    "    with tf.name_scope(\"layer2\") as scope:\n",
    "        A2 = tf.sigmoid(tf.matmul(x_input, Theta1) + Bias1)\n",
    "\n",
    "    with tf.name_scope(\"layer3\") as scope:\n",
    "        Hypothesis = tf.sigmoid(tf.matmul(A2, Theta2) + Bias2)\n",
    "\n",
    "    with tf.name_scope(\"cost\") as scope:\n",
    "        cost = tf.reduce_mean(( (y_label * tf.log(Hypothesis)) + ((1 - y_label) * tf.log(1.0 - Hypothesis)) ) * -1)\n",
    "\n",
    "    with tf.name_scope(\"train\") as scope:\n",
    "        train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "        \n",
    "    with tf.name_scope(\"accuracy\") as scope:\n",
    "        correct_prediction = tf.equal(y_label , tf.to_float(tf.to_int32(Hypothesis > 0.5)))# argmax along dim-1\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\")) # [True, False, True, True] -> [1,0,1,1] -> 0.75.\n",
    "        \n",
    "    var_init_op = tf.global_variables_initializer()\n",
    "        \n",
    "with tf.Session(graph=g) as sess:\n",
    "    # start run the seesion and meet the requrements\n",
    "    # from here \n",
    "    sess.run(var_init_op)\n",
    "    for i in range(20000):\n",
    "        sess.run(train_step, feed_dict={x_input: xor_data, y_label: xor_label})\n",
    "#         if i%10000==0 or i==100000-1:\n",
    "    print('Epoch ', i)\n",
    "    print('Hypothesis ', sess.run(Hypothesis, feed_dict={x_input: xor_data, y_label: xor_label}))\n",
    "    print('Theta1 ', sess.run(Theta1))\n",
    "    print('Bias1 ', sess.run(Bias1))\n",
    "    print('Theta2 ', sess.run(Theta2))\n",
    "    print('Bias2 ', sess.run(Bias2))\n",
    "    print('cost ', sess.run(cost, feed_dict={x_input: xor_data, y_label: xor_label}))\n",
    "    print('accuracy: ',sess.run(accuracy, feed_dict={x_input: xor_data, y_label: xor_label}))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-e70db4c1b96c>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/mnist/t10k-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# load mnist data\n",
    "mnist = input_data.read_data_sets(\"data/mnist\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: 55000\n",
      "validation data size: 5000\n",
      "testing data size: 10000\n",
      "Shape of image: (784,)\n",
      "Shape of label: (10,)\n"
     ]
    }
   ],
   "source": [
    "print(\"training data size: {}\".format(mnist.train.num_examples))\n",
    "print(\"validation data size: {}\".format(mnist.validation.num_examples))\n",
    "print(\"testing data size: {}\".format(mnist.test.num_examples))\n",
    "\n",
    "print(\"Shape of image: {}\".format(mnist.train.images[0].shape))\n",
    "print(\"Shape of label: {}\".format(mnist.train.labels[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1296 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 5\n",
    "plt.figure(figsize=(18,18))\n",
    "for i in range(5):\n",
    "    plt.subplot(n, n, i+1)\n",
    "    plt.imshow(mnist.train.images[i].reshape(28,28), cmap='gray')\n",
    "    plt.title(np.argmax(mnist.train.labels[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-27-d4dd088a009c>:40: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "test accuracy:  0.9504\n",
      "test iteration:  8426\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default() as g:\n",
    "    ## meet the requirements\n",
    "    ## then you will\n",
    "    # setting \n",
    "    feature_dims = 784 # example with 784 features\n",
    "    neurons = 2000 # fully connected layer with 1024 neurons\n",
    "    classes = 10 # 10 classes classification problem\n",
    "    x_input = tf.placeholder( tf.float32 ,  [None, feature_dims] , name='x_input' )\n",
    "    y_label = tf.placeholder( tf.float32 , [None, classes] , name='y_label' )\n",
    "    p_keep_input = tf.placeholder(tf.float32)\n",
    "    p_keep_hidden = tf.placeholder(tf.float32)\n",
    "    number_hidden_nodes1 = 1024\n",
    "    number_hidden_nodes2 = 625\n",
    "    Theta1 = tf.Variable(tf.random_uniform([feature_dims , number_hidden_nodes1], -1, 1), name = \"Theta1\")\n",
    "    Theta2 = tf.Variable(tf.random_uniform([number_hidden_nodes1 , number_hidden_nodes2], -1, 1), name = \"Theta2\")\n",
    "    Theta3 = tf.Variable(tf.random_uniform([number_hidden_nodes2,classes], -1, 1), name = \"Theta3\")\n",
    "#     Bias1 = tf.Variable(tf.zeros([number_hidden_nodes]), name = \"Bias1\")\n",
    "#     Bias2 = tf.Variable(tf.zeros([number_hidden_nodes1]), name = \"Bias2\")\n",
    "#     Bias3 = tf.Variable(tf.zeros([classes]), name = \"Bias3\")\n",
    "    \n",
    "    def fully_connected_layer(x_inputs, weights,name='fc'):\n",
    "        with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
    "            out = tf.nn.relu(tf.matmul(x_inputs, weights))\n",
    "            return out\n",
    "    with tf.name_scope(\"layer2\") as scope:\n",
    "        x_input = tf.nn.dropout(x_input, p_keep_input)\n",
    "        A2 = fully_connected_layer(x_input,Theta1)\n",
    "        A2 = tf.nn.dropout(A2, p_keep_hidden)\n",
    "    \n",
    "    with tf.name_scope(\"layer3\") as scope:\n",
    "        A3 = fully_connected_layer(A2,Theta2)\n",
    "        A3 = tf.nn.dropout(A3, p_keep_hidden)\n",
    "\n",
    "    with tf.name_scope(\"layer4\") as scope:\n",
    "        Hypothesis = tf.matmul(A3, Theta3)\n",
    "\n",
    "    with tf.name_scope(\"cost\") as scope:\n",
    "#         cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1])) ; y_label Hypothesis\n",
    "#         cost = tf.reduce_mean(-tf.reduce_sum(y_label * tf.clip_by_value(Hypothesis, 1e-10, 1.0), reduction_indices=[1]))\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Hypothesis, labels=y_label))\n",
    "\n",
    "    with tf.name_scope(\"train\") as scope:\n",
    "#         train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "          train_step = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)\n",
    "#         train_step = tf.train.MomentumOptimizer(learning_rate=0.1, momentum=0.9).minimize(cost)\n",
    "        \n",
    "    with tf.name_scope(\"accuracy\") as scope:\n",
    "        correct_prediction = tf.equal(tf.argmax(y_label, 1), tf.argmax(Hypothesis, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "    var_init_op = tf.global_variables_initializer()\n",
    "    \n",
    "with tf.Session(graph=g) as sess:\n",
    "    ## just do it\n",
    "    sess.run(var_init_op)\n",
    "    batch_size = 100\n",
    "    keep_input = 0.8\n",
    "    keep_hidden = 0.75\n",
    "    num_data = mnist.train.num_examples + mnist.validation.num_examples\n",
    "    for i in range(30000):\n",
    "        input_images, correct_predictions = mnist.train.next_batch(batch_size)\n",
    "        test_acc = sess.run(accuracy, feed_dict={x_input: mnist.test.images, y_label: mnist.test.labels,p_keep_input: keep_input, p_keep_hidden: keep_hidden})\n",
    "        if test_acc >= 0.95:\n",
    "            print('test accuracy: ',test_acc)\n",
    "            print('test iteration: ',i)\n",
    "            break\n",
    "#             print('cost ', sess.run(cost, feed_dict={x_input: input_images, y_label: correct_predictions,p_keep_input: keep_input, p_keep_hidden: keep_hidden}))\n",
    "        sess.run(train_step, feed_dict={x_input: input_images, y_label: correct_predictions,p_keep_input: keep_input, p_keep_hidden: keep_hidden})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
