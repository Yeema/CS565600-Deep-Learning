{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "      <td>193</td>\n",
       "      <td>371</td>\n",
       "      <td>174</td>\n",
       "      <td>121</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>49.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>174</td>\n",
       "      <td>401</td>\n",
       "      <td>149</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>38.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>95</td>\n",
       "      <td>138</td>\n",
       "      <td>163</td>\n",
       "      <td>386</td>\n",
       "      <td>185</td>\n",
       "      <td>102</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   270  271  272  273  \\\n",
       "0   75    0  190   80   91  193  371  174  121  -16 ...   0.0  9.0 -0.9  0.0   \n",
       "1   56    1  165   64   81  174  401  149   39   25 ...   0.0  8.5  0.0  0.0   \n",
       "2   54    0  172   95  138  163  386  185  102   96 ...   0.0  9.5 -2.4  0.0   \n",
       "\n",
       "   274  275  276   277   278  279  \n",
       "0  0.0  0.9  2.9  23.3  49.4    8  \n",
       "1  0.0  0.2  2.1  20.4  38.8    6  \n",
       "2  0.0  0.3  3.4  12.3  49.0   10  \n",
       "\n",
       "[3 rows x 280 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "#load the data\n",
    "data = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/'\n",
    "                   'arrhythmia/arrhythmia.data', header=None, sep=',', engine='python')\n",
    "\n",
    "display(data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452 rows and 280 columns\n"
     ]
    }
   ],
   "source": [
    "print('%d rows and %d columns' % (data.shape[0],data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 14, 15, 16])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data[len(data.columns)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['arrhythmia'] = data[len(data.columns)-1].map(lambda x: 0 if x==1 else 1)\n",
    "data = data.drop(len(data.columns)-2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arrhythmia\n",
       "0    245\n",
       "1    207\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['arrhythmia']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452 rows and 275 columns\n"
     ]
    }
   ],
   "source": [
    "data = data._get_numeric_data()\n",
    "print('%d rows and %d columns' % (data.shape[0],data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>arrhythmia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "      <td>193</td>\n",
       "      <td>371</td>\n",
       "      <td>174</td>\n",
       "      <td>121</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>49.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>174</td>\n",
       "      <td>401</td>\n",
       "      <td>149</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>38.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>95</td>\n",
       "      <td>138</td>\n",
       "      <td>163</td>\n",
       "      <td>386</td>\n",
       "      <td>185</td>\n",
       "      <td>102</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 275 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  1    2   3    4    5    6    7    8   9     ...      270  271  272  \\\n",
       "0  75  0  190  80   91  193  371  174  121 -16     ...      0.0  9.0 -0.9   \n",
       "1  56  1  165  64   81  174  401  149   39  25     ...      0.0  8.5  0.0   \n",
       "2  54  0  172  95  138  163  386  185  102  96     ...      0.0  9.5 -2.4   \n",
       "\n",
       "   273  274  275  276   277   278  arrhythmia  \n",
       "0  0.0  0.0  0.9  2.9  23.3  49.4           1  \n",
       "1  0.0  0.0  0.2  2.1  20.4  38.8           1  \n",
       "2  0.0  0.0  0.3  3.4  12.3  49.0           1  \n",
       "\n",
       "[3 rows x 275 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "(452, 274)\n",
      "(452,)\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:, :-1]  # The first to second-last columns are the features\n",
    "y = data.iloc[:, -1]   # The last column is the ground-truth label\n",
    "print(np.unique(y))\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splitting the dataset to training and validation datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20181004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardizing the training and test datasets\n",
    "# Note that we are scaling based on the information from the training data\n",
    "# Then we apply the scaling that is done from training data to the test data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression(object):\n",
    "\n",
    "    def __init__(self, eta=0.00005, n_epoch=1000, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_epoch = n_epoch\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
    "        self.cost_ = []\n",
    "\n",
    "        for i in range(self.n_epoch):\n",
    "            net_input = self.net_input(X)\n",
    "            output = self.activation(net_input)\n",
    "            errors = (y - output)\n",
    "            self.w_[1:] += self.eta * X.T.dot(errors)\n",
    "            self.w_[0] += self.eta * errors.sum()\n",
    "            cost = self.loss(output, y)\n",
    "            self.cost_.append(cost)\n",
    "        return self\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def loss(self, output, y):\n",
    "        \"\"\"Calculate loss\"\"\"\n",
    "        # TODO\n",
    "        return (-y * np.log(output) - (1-y) * np.log( 1 - output )).mean()\n",
    "    \n",
    "    def activation(self, z):\n",
    "        \"\"\"Compute logistic sigmoid activation\"\"\"\n",
    "        # TODO\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        # TODO\n",
    "        return np.where(self.activation(self.net_input(X)) >= 0.555, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def F1_score(tags,predicted):\n",
    "#     tags = set(tags)\n",
    "#     predicted = set(predicted)\n",
    "    tags = np.array(tags.tolist())\n",
    "    tp = 0 \n",
    "    fp = 0\n",
    "    fn = 0 \n",
    "    for i in range(tags.shape[0]):\n",
    "        if tags[i]== predicted[i]:\n",
    "            if tags[i] == 0:\n",
    "                tp += 1 \n",
    "        else:\n",
    "            if predicted[i] == 1:\n",
    "                fn += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "    if tp>0:\n",
    "        precision=float(tp)/(tp+fp)\n",
    "        recall=float(tp)/(tp+fn)\n",
    "\n",
    "        return 2*((precision*recall)/(precision+recall))\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "lreg = LogisticRegression(0.005,100)\n",
    "lreg.fit(X_train_std, y_train)\n",
    "y_pred = lreg.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score: 0.75\n"
     ]
    }
   ],
   "source": [
    "f = F1_score(y_test, y_pred)\n",
    "print('f1-score: %.2f' % (f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASQAAAEmCAYAAADLMe3nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb28824c400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
    "\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./output/fig-logistic-regression-confusion-2.png', dpi=300)\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(20)\n",
    "for item in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
